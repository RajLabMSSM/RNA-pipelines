Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	createDegradationMatrix
	2

[Mon Oct 28 14:27:25 2019]
rule createDegradationMatrix:
    input: input/test.bam, input/test.bam.bai
    output: output/test.degradation_matrix.tsv
    jobid: 1
    reason: Missing output files: output/test.degradation_matrix.tsv
    wildcards: samples=test

/usr/bin/python2.7 scripts/region_matrix.py --regions regions/sorted_ribozero_degradation_regions_v2.bed --bams input/test.bam  --wiggletools $(which wiggletools)  -p 1  > output/test.degradation_matrix.tsv
[Mon Oct 28 14:27:28 2019]
Finished job 1.
1 of 2 steps (50%) done

[Mon Oct 28 14:27:28 2019]
localrule all:
    input: output/test.degradation_matrix.tsv
    jobid: 0
    reason: Input files updated by another job: output/test.degradation_matrix.tsv

[Mon Oct 28 14:27:28 2019]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /hpc/users/humphj04/pipelines/qSVA-pipeline/.snakemake/log/2019-10-28T142725.477769.snakemake.log
